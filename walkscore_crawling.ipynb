{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install bs4\n",
    "!pip install lexml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번 째 크롤링 중\n",
      "5번 째 크롤링 중\n",
      "10번 째 크롤링 중\n",
      "15번 째 크롤링 중\n",
      "20번 째 크롤링 중\n",
      "25번 째 크롤링 중\n",
      "30번 째 크롤링 중\n",
      "35번 째 크롤링 중\n",
      "40번 째 크롤링 중\n",
      "45번 째 크롤링 중\n",
      "50번 째 크롤링 중\n",
      "55번 째 크롤링 중\n",
      "60번 째 크롤링 중\n",
      "65번 째 크롤링 중\n",
      "70번 째 크롤링 중\n",
      "75번 째 크롤링 중\n",
      "80번 째 크롤링 중\n",
      "85번 째 크롤링 중\n",
      "90번 째 크롤링 중\n",
      "95번 째 크롤링 중\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests  \n",
    "from bs4 import BeautifulSoup\n",
    "import lxml.html\n",
    "\n",
    "os.chdir('C:/Users/q/walkscore')\n",
    "\n",
    "data= pd.read_csv('S3_samples_address.csv')\n",
    "\n",
    "def save(score_list,idx):\n",
    "    result = pd.DataFrame(score_list,columns=['walkscore','url'])\n",
    "    result = pd.concat([data,result],axis=1)\n",
    "    result.to_csv(str(idx)+'개 crwaler walkscore.csv')\n",
    "\n",
    "\n",
    "def parsing(idx):\n",
    "    try:\n",
    "        data_address = data.loc[idx]\n",
    "        address_url = \"-\".join(data_address['address'].lower().split(' '))\n",
    "        county_url = \"-\".join(data_address['county'].lower().split(' '))\n",
    "\n",
    "        state_url = \"-\".join(data_address['state'].lower().split(' '))\n",
    "        zip_url = data_address['zip']\n",
    "\n",
    "\n",
    "        url = 'https://www.walkscore.com/score/' + address_url + '-' + county_url +'-' +  state_url +'-'  + str(int(zip_url))\n",
    "\n",
    "        res = requests.get(url)\n",
    "        e = lxml.html.fromstring(res.content) \n",
    "        score  = e.xpath('//*[@id=\"address-header\"]/div/div[1]/div[1]/div/img')[0].get('src').split('score/')[1].split('.svg')[0]\n",
    "    except:\n",
    "        score = '에러\n",
    "        url = '에러'\n",
    "\n",
    "    \n",
    "    return score,url\n",
    "\n",
    "score_list = []\n",
    "for idx in range(len(data))\n",
    "    score= parsing(idx)\n",
    "    score_list.append(score)\n",
    "    #크롤링 100개씩 프린트\n",
    "    if idx%100==0:\n",
    "        print(str(idx)+ '번 째 크롤링 중')\n",
    "    #\n",
    "    if idx%500==0:\n",
    "        save(score_list,idx)\n",
    "save(score_list,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
